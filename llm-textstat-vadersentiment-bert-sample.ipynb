{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LMSYS - Chatbot Arena Human Preference Predictions\n\n","metadata":{}},{"cell_type":"markdown","source":"**Due to the size of the train data, and I only using 0.5% of the train data!**\n\nWIP: Compute embeddings using TPU in a differente notebook to use the full train data and then load the embeddings here!","metadata":{}},{"cell_type":"markdown","source":"## Install and load libraries","metadata":{}},{"cell_type":"code","source":"!pip install textstat SweetViz","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:33:41.415887Z","iopub.execute_input":"2024-07-15T10:33:41.416352Z","iopub.status.idle":"2024-07-15T10:33:59.382928Z","shell.execute_reply.started":"2024-07-15T10:33:41.416315Z","shell.execute_reply":"2024-07-15T10:33:59.381338Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting textstat\n  Downloading textstat-0.7.3-py3-none-any.whl.metadata (14 kB)\nCollecting SweetViz\n  Downloading sweetviz-2.3.1-py3-none-any.whl.metadata (24 kB)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.15.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (2.2.2)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (1.26.4)\nRequirement already satisfied: matplotlib>=3.1.3 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (3.7.5)\nRequirement already satisfied: tqdm>=4.43.0 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (4.66.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (1.11.4)\nRequirement already satisfied: jinja2>=2.11.1 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (3.1.2)\nRequirement already satisfied: importlib-resources>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from SweetViz) (6.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.1->SweetViz) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.1.3->SweetViz) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->SweetViz) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->SweetViz) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->SweetViz) (1.16.0)\nDownloading textstat-0.7.3-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sweetviz-2.3.1-py3-none-any.whl (15.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, textstat, SweetViz\nSuccessfully installed SweetViz-2.3.1 pyphen-0.15.0 textstat-0.7.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport sweetviz as sv\n\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport textstat\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom transformers import BertTokenizer, TFBertModel\n\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.metrics import accuracy_score, \\\n                            log_loss, \\\n                            confusion_matrix, \\\n                            classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-15T10:33:59.385457Z","iopub.execute_input":"2024-07-15T10:33:59.385882Z","iopub.status.idle":"2024-07-15T10:34:26.626598Z","shell.execute_reply.started":"2024-07-15T10:33:59.385844Z","shell.execute_reply":"2024-07-15T10:34:26.625291Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-15 10:34:06.802877: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-15 10:34:06.803044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-15 10:34:06.979292: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('stopwords')\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:26.628304Z","iopub.execute_input":"2024-07-15T10:34:26.629331Z","iopub.status.idle":"2024-07-15T10:34:26.705902Z","shell.execute_reply.started":"2024-07-15T10:34:26.629283Z","shell.execute_reply":"2024-07-15T10:34:26.704543Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\ntest_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:26.708734Z","iopub.execute_input":"2024-07-15T10:34:26.709185Z","iopub.status.idle":"2024-07-15T10:34:30.485346Z","shell.execute_reply.started":"2024-07-15T10:34:26.709137Z","shell.execute_reply":"2024-07-15T10:34:30.483633Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"train_analysis = sv.analyze(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:30.486668Z","iopub.execute_input":"2024-07-15T10:34:30.487034Z","iopub.status.idle":"2024-07-15T10:34:39.325863Z","shell.execute_reply.started":"2024-07-15T10:34:30.487001Z","shell.execute_reply":"2024-07-15T10:34:39.324240Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                             |          | [  0%]   00:00 -> (? left)","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c26c8c06fb422f9b2e34e181b3a90f"}},"metadata":{}}]},{"cell_type":"code","source":"train_analysis.show_html('train_analysis.html')","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:39.327819Z","iopub.execute_input":"2024-07-15T10:34:39.328624Z","iopub.status.idle":"2024-07-15T10:34:39.677260Z","shell.execute_reply.started":"2024-07-15T10:34:39.328578Z","shell.execute_reply":"2024-07-15T10:34:39.675712Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Report train_analysis.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:39.678987Z","iopub.execute_input":"2024-07-15T10:34:39.679353Z","iopub.status.idle":"2024-07-15T10:34:39.700291Z","shell.execute_reply.started":"2024-07-15T10:34:39.679322Z","shell.execute_reply":"2024-07-15T10:34:39.699087Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Training Data -\", train_data.shape)\nprint(\"Test Data -\", test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:39.701764Z","iopub.execute_input":"2024-07-15T10:34:39.702126Z","iopub.status.idle":"2024-07-15T10:34:39.708363Z","shell.execute_reply.started":"2024-07-15T10:34:39.702092Z","shell.execute_reply":"2024-07-15T10:34:39.707161Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training Data - (57477, 9)\nTest Data - (3, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.describe(include=['O'])","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:39.709973Z","iopub.execute_input":"2024-07-15T10:34:39.710466Z","iopub.status.idle":"2024-07-15T10:34:39.979519Z","shell.execute_reply.started":"2024-07-15T10:34:39.710412Z","shell.execute_reply":"2024-07-15T10:34:39.977988Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                   model_a             model_b  \\\ncount                57477               57477   \nunique                  64                  64   \ntop     gpt-4-1106-preview  gpt-4-1106-preview   \nfreq                  3678                3709   \n\n                                                   prompt  \\\ncount                                               57477   \nunique                                              51734   \ntop     [\"Answer the following statements with \\\"Agree...   \nfreq                                                  101   \n\n                                    response_a  \\\ncount                                    57477   \nunique                                   56566   \ntop     [\"Hello! How can I assist you today?\"]   \nfreq                                       109   \n\n                                    response_b  \ncount                                    57477  \nunique                                   56609  \ntop     [\"Hello! How can I assist you today?\"]  \nfreq                                       100  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>57477</td>\n      <td>57477</td>\n      <td>57477</td>\n      <td>57477</td>\n      <td>57477</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>64</td>\n      <td>64</td>\n      <td>51734</td>\n      <td>56566</td>\n      <td>56609</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-1106-preview</td>\n      <td>[\"Answer the following statements with \\\"Agree...</td>\n      <td>[\"Hello! How can I assist you today?\"]</td>\n      <td>[\"Hello! How can I assist you today?\"]</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>3678</td>\n      <td>3709</td>\n      <td>101</td>\n      <td>109</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(train_data.info())","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:39.985109Z","iopub.execute_input":"2024-07-15T10:34:39.985526Z","iopub.status.idle":"2024-07-15T10:34:40.039905Z","shell.execute_reply.started":"2024-07-15T10:34:39.985495Z","shell.execute_reply":"2024-07-15T10:34:40.038678Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.drop(\"id\", axis=1).duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:40.041135Z","iopub.execute_input":"2024-07-15T10:34:40.041517Z","iopub.status.idle":"2024-07-15T10:34:40.551835Z","shell.execute_reply.started":"2024-07-15T10:34:40.041484Z","shell.execute_reply":"2024-07-15T10:34:40.550554Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"7"},"metadata":{}}]},{"cell_type":"markdown","source":"There exist 14 duplicated rows forming 7 groups, I will just keep one row per group.","metadata":{}},{"cell_type":"code","source":"train_data = train_data.drop_duplicates(keep=\"first\", ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:40.553437Z","iopub.execute_input":"2024-07-15T10:34:40.553930Z","iopub.status.idle":"2024-07-15T10:34:41.059542Z","shell.execute_reply.started":"2024-07-15T10:34:40.553889Z","shell.execute_reply":"2024-07-15T10:34:41.058435Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Checking the quality of the train data with respect the `id` column.","metadata":{}},{"cell_type":"code","source":"train_data.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:41.060808Z","iopub.execute_input":"2024-07-15T10:34:41.061181Z","iopub.status.idle":"2024-07-15T10:34:41.603340Z","shell.execute_reply.started":"2024-07-15T10:34:41.061135Z","shell.execute_reply":"2024-07-15T10:34:41.602224Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"id                57477\nmodel_a              64\nmodel_b              64\nprompt            51734\nresponse_a        56566\nresponse_b        56609\nwinner_model_a        2\nwinner_model_b        2\nwinner_tie            2\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"assert train_data[\"id\"].nunique() == len(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:41.605228Z","iopub.execute_input":"2024-07-15T10:34:41.605597Z","iopub.status.idle":"2024-07-15T10:34:41.613706Z","shell.execute_reply.started":"2024-07-15T10:34:41.605566Z","shell.execute_reply":"2024-07-15T10:34:41.612720Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:41.615071Z","iopub.execute_input":"2024-07-15T10:34:41.615433Z","iopub.status.idle":"2024-07-15T10:34:41.666185Z","shell.execute_reply.started":"2024-07-15T10:34:41.615402Z","shell.execute_reply":"2024-07-15T10:34:41.664758Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"id                0\nmodel_a           0\nmodel_b           0\nprompt            0\nresponse_a        0\nresponse_b        0\nwinner_model_a    0\nwinner_model_b    0\nwinner_tie        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"### Distribution","metadata":{}},{"cell_type":"code","source":"model_df = pd.concat([train_data.model_a, train_data.model_b])\ncounts = model_df.value_counts().reset_index()\ncounts.columns = ['LLM', 'Count']\n\n# Create a bar plot with custom styling using Plotly\nfig = px.bar(counts, x='LLM', y='Count',\n             title='Distribution of LLMs',\n             color='Count')\n\nfig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:41.667864Z","iopub.execute_input":"2024-07-15T10:34:41.668356Z","iopub.status.idle":"2024-07-15T10:34:43.906370Z","shell.execute_reply.started":"2024-07-15T10:34:41.668315Z","shell.execute_reply":"2024-07-15T10:34:43.905165Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"66189df2-18f3-47ae-900c-d0aa349a4652\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"66189df2-18f3-47ae-900c-d0aa349a4652\")) {                    Plotly.newPlot(                        \"66189df2-18f3-47ae-900c-d0aa349a4652\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"LLM=%{x}\\u003cbr\\u003eCount=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[7387,7083,6165,5583,4136,4122,3978,3720,3545,3448,3428,3352,3315,2607,2456,2401,1977,1793,1644,1632,1617,1598,1591,1580,1494,1486,1474,1447,1438,1420,1403,1302,1261,1250,1200,1160,1158,1134,1072,1021,989,952,928,914,899,861,800,795,771,684,667,598,564,551,547,412,408,373,325,286,244,208,200,100],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"gpt-4-1106-preview\",\"gpt-3.5-turbo-0613\",\"gpt-4-0613\",\"claude-2.1\",\"claude-instant-1\",\"gpt-4-0314\",\"claude-1\",\"vicuna-33b\",\"mixtral-8x7b-instruct-v0.1\",\"vicuna-13b\",\"llama-2-70b-chat\",\"gpt-3.5-turbo-1106\",\"mistral-medium\",\"llama-2-13b-chat\",\"claude-2.0\",\"zephyr-7b-beta\",\"palm-2\",\"llama-2-7b-chat\",\"wizardlm-70b\",\"openchat-3.5\",\"mistral-7b-instruct\",\"koala-13b\",\"vicuna-7b\",\"wizardlm-13b\",\"oasst-pythia-12b\",\"gemini-pro-dev-api\",\"codellama-34b-instruct\",\"yi-34b-chat\",\"gemini-pro\",\"pplx-70b-online\",\"alpaca-13b\",\"gpt-3.5-turbo-0314\",\"chatglm-6b\",\"pplx-7b-online\",\"tulu-2-dpo-70b\",\"gpt-4-0125-preview\",\"RWKV-4-Raven-14B\",\"starling-lm-7b-alpha\",\"qwen-14b-chat\",\"fastchat-t5-3b\",\"chatglm3-6b\",\"openhermes-2.5-mistral-7b\",\"mpt-7b-chat\",\"stripedhyena-nous-7b\",\"solar-10.7b-instruct-v1.0\",\"gpt-3.5-turbo-0125\",\"dolly-v2-12b\",\"deepseek-llm-67b-chat\",\"stablelm-tuned-alpha-7b\",\"guanaco-33b\",\"llama2-70b-steerlm-chat\",\"mpt-30b-chat\",\"chatglm2-6b\",\"qwen1.5-72b-chat\",\"llama-13b\",\"zephyr-7b-alpha\",\"gpt4all-13b-snoozy\",\"dolphin-2.2.1-mistral-7b\",\"nous-hermes-2-mixtral-8x7b-dpo\",\"falcon-180b-chat\",\"openchat-3.5-0106\",\"qwen1.5-7b-chat\",\"qwen1.5-4b-chat\",\"mistral-7b-instruct-v0.2\"],\"xaxis\":\"x\",\"y\":[7387,7083,6165,5583,4136,4122,3978,3720,3545,3448,3428,3352,3315,2607,2456,2401,1977,1793,1644,1632,1617,1598,1591,1580,1494,1486,1474,1447,1438,1420,1403,1302,1261,1250,1200,1160,1158,1134,1072,1021,989,952,928,914,899,861,800,795,771,684,667,598,564,551,547,412,408,373,325,286,244,208,200,100],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"LLM\"},\"tickangle\":-45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Count\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Distribution of LLMs\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('66189df2-18f3-47ae-900c-d0aa349a4652');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"counts_a = train_data['winner_model_a'].value_counts().reset_index()\ncounts_b = train_data['winner_model_b'].value_counts().reset_index()\ncounts_tie = train_data['winner_tie'].value_counts().reset_index()\n\n# Renaming columns for convinience\ncounts_a.columns = ['Winner', 'Count']\ncounts_b.columns = ['Winner', 'Count']\ncounts_tie.columns = ['Winner', 'Count']\n\n# Adding column to identify the model\ncounts_a['Model'] = 'Model A'\ncounts_b['Model'] = 'Model B'\ncounts_tie['Model'] = 'Tie'\n\ncounts = pd.concat([counts_a, counts_b, counts_tie])\n\nfig = px.bar(counts, x='Model', y='Count', \n             color='Model',\n             title='Winner Distribution for Train Data',\n             labels={'Model': 'Model', 'Count': 'Win Count', 'Winner': 'Winner'})\n\nfig.update_layout(xaxis_title=\"Model\", yaxis_title=\"Win Count\")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:43.907864Z","iopub.execute_input":"2024-07-15T10:34:43.908277Z","iopub.status.idle":"2024-07-15T10:34:44.035778Z","shell.execute_reply.started":"2024-07-15T10:34:43.908231Z","shell.execute_reply":"2024-07-15T10:34:44.034645Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"bb9333e4-30b9-4342-ac66-2ec41124fdcd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bb9333e4-30b9-4342-ac66-2ec41124fdcd\")) {                    Plotly.newPlot(                        \"bb9333e4-30b9-4342-ac66-2ec41124fdcd\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Model=%{x}\\u003cbr\\u003eWin Count=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Model A\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Model A\",\"offsetgroup\":\"Model A\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Model A\",\"Model A\"],\"xaxis\":\"x\",\"y\":[37413,20064],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Model=%{x}\\u003cbr\\u003eWin Count=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Model B\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Model B\",\"offsetgroup\":\"Model B\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Model B\",\"Model B\"],\"xaxis\":\"x\",\"y\":[37825,19652],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Model=%{x}\\u003cbr\\u003eWin Count=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Tie\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Tie\",\"offsetgroup\":\"Tie\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Tie\",\"Tie\"],\"xaxis\":\"x\",\"y\":[39716,17761],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Model\"},\"categoryorder\":\"array\",\"categoryarray\":[\"Model A\",\"Model B\",\"Tie\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Win Count\"}},\"legend\":{\"title\":{\"text\":\"Model\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Winner Distribution for Train Data\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('bb9333e4-30b9-4342-ac66-2ec41124fdcd');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Conclusions:\n\n* There are 57477 training rows and 3 test rows.\n    * Note: Test data will be replaced with the full test set (~25k rows, 70% for private LB) during scoring phase.\n* The column `id` has no duplicated values.\n* Model identities aren't revealed in the test set.\n* Strings in columns prompt, `response_a`, and `response_a` are wrapped in a list. \n    * The reason is that each chat can contains more than one prompt/response pairs.\n* After dropping `id` column, there exist 14 duplicated rows forming 7 groups, we just keep one row per group and shape of the training DataFrame becomes (57470, 8).","metadata":{}},{"cell_type":"markdown","source":"## Data preparation and Feature Engineering\n\n* Cleaning data: clean text, such as removing special characters, normalizing to lowercase, removing stopwords and tokenizing.\n* Tokenize Inputs: using the TensorFlow/Kerar tokenizer by training on training data and fitting on both training and test data.\n* Padding sequences to `max_len`.\n* Create BERT embeddings.\n* Compute Similarity Features using BERT between the prompt and responses for each model. \n* Compute word count, character count, and lexical diversity for each response.\n* Tokenize the text inputs for the BERT model.","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv').sample(frac=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:44.037333Z","iopub.execute_input":"2024-07-15T10:34:44.037769Z","iopub.status.idle":"2024-07-15T10:34:46.277777Z","shell.execute_reply.started":"2024-07-15T10:34:44.037729Z","shell.execute_reply":"2024-07-15T10:34:46.276634Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Cleaning data\n\nClean text, such as removing special characters, normalizing to lowercase and removing stopwords.","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\[.*?\\]', '', text)\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub(r'<.*?>+', '', text)\n    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub(r'\\n', '', text)\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    text = ' '.join(word for word in text.split() if word not in stop_words)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.280195Z","iopub.execute_input":"2024-07-15T10:34:46.280599Z","iopub.status.idle":"2024-07-15T10:34:46.288610Z","shell.execute_reply.started":"2024-07-15T10:34:46.280566Z","shell.execute_reply":"2024-07-15T10:34:46.287229Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Cleaning texts\ntrain_data['prompt_clean'] = train_data['prompt'].apply(clean_text)\ntrain_data['response_a_clean'] = train_data['response_a'].apply(clean_text)\ntrain_data['response_b_clean'] = train_data['response_b'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.290311Z","iopub.execute_input":"2024-07-15T10:34:46.290769Z","iopub.status.idle":"2024-07-15T10:34:46.316756Z","shell.execute_reply.started":"2024-07-15T10:34:46.290725Z","shell.execute_reply":"2024-07-15T10:34:46.315617Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize Inputs\n\nUsing the TensorFlow/Kerar tokenizer on both training and test data. Padding sequences to `max_len`.","metadata":{}},{"cell_type":"code","source":"max_len = 512","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.318825Z","iopub.execute_input":"2024-07-15T10:34:46.319341Z","iopub.status.idle":"2024-07-15T10:34:46.326669Z","shell.execute_reply.started":"2024-07-15T10:34:46.319296Z","shell.execute_reply":"2024-07-15T10:34:46.325432Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=20000)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.328108Z","iopub.execute_input":"2024-07-15T10:34:46.328517Z","iopub.status.idle":"2024-07-15T10:34:46.336728Z","shell.execute_reply.started":"2024-07-15T10:34:46.328475Z","shell.execute_reply":"2024-07-15T10:34:46.335637Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit_on_texts(pd.concat([train_data['prompt_clean'], train_data['response_a_clean'], train_data['response_b_clean']]))","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.338196Z","iopub.execute_input":"2024-07-15T10:34:46.338587Z","iopub.status.idle":"2024-07-15T10:34:46.355879Z","shell.execute_reply.started":"2024-07-15T10:34:46.338554Z","shell.execute_reply":"2024-07-15T10:34:46.354609Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(train_data['prompt_clean'])\nresponse_a_sequences = tokenizer.texts_to_sequences(train_data['response_a_clean'])\nresponse_b_sequences = tokenizer.texts_to_sequences(train_data['response_b_clean'])","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.357412Z","iopub.execute_input":"2024-07-15T10:34:46.357828Z","iopub.status.idle":"2024-07-15T10:34:46.369590Z","shell.execute_reply.started":"2024-07-15T10:34:46.357793Z","shell.execute_reply":"2024-07-15T10:34:46.368430Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Padding\ntrain_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post')\nresponse_a_sequences = pad_sequences(response_a_sequences, maxlen=max_len, padding='post')\nresponse_b_sequences = pad_sequences(response_b_sequences, maxlen=max_len, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.371170Z","iopub.execute_input":"2024-07-15T10:34:46.371665Z","iopub.status.idle":"2024-07-15T10:34:46.382058Z","shell.execute_reply.started":"2024-07-15T10:34:46.371623Z","shell.execute_reply":"2024-07-15T10:34:46.380991Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Sentiment Analysis\n\nSentiment analysis using `vaderSentiment`. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media","metadata":{}},{"cell_type":"code","source":"analyzer = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.383538Z","iopub.execute_input":"2024-07-15T10:34:46.383920Z","iopub.status.idle":"2024-07-15T10:34:46.410086Z","shell.execute_reply.started":"2024-07-15T10:34:46.383888Z","shell.execute_reply":"2024-07-15T10:34:46.409070Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def sentiment_analysis(text):\n    return analyzer.polarity_scores(text)['compound']","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.411397Z","iopub.execute_input":"2024-07-15T10:34:46.411742Z","iopub.status.idle":"2024-07-15T10:34:46.416930Z","shell.execute_reply.started":"2024-07-15T10:34:46.411701Z","shell.execute_reply":"2024-07-15T10:34:46.415620Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_data['sentiment_prompt'] = train_data['prompt_clean'].apply(sentiment_analysis)\ntrain_data['sentiment_response_a'] = train_data['response_a_clean'].apply(sentiment_analysis)\ntrain_data['sentiment_response_b'] = train_data['response_b_clean'].apply(sentiment_analysis)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.427898Z","iopub.execute_input":"2024-07-15T10:34:46.428431Z","iopub.status.idle":"2024-07-15T10:34:46.466980Z","shell.execute_reply.started":"2024-07-15T10:34:46.428396Z","shell.execute_reply":"2024-07-15T10:34:46.465660Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Text Features\n\nCalculate text features such as word count, character count, \nlexical diversity, syllable count, sentence count and \ncalculating the Flesch Reading Ease score (quantitative \nmeasurement of how readable a piece of text is) for each response. \n\nI am using `textstat` library that analyze text statistics.","metadata":{}},{"cell_type":"code","source":"def word_count(text):\n    return len(text.split())\n\ndef char_count(text):\n    return len(text)\n\ndef lexical_diversity(text):\n    words = text.split()\n    return len(set(words)) / len(words) if words else 0\n\ndef syllable_count(text):\n    return textstat.syllable_count(text)\n\ndef sentence_count(text):\n    return textstat.sentence_count(text)\n\ndef flesch_reading_ease(text):\n    return textstat.flesch_reading_ease(text)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.468702Z","iopub.execute_input":"2024-07-15T10:34:46.469188Z","iopub.status.idle":"2024-07-15T10:34:46.479754Z","shell.execute_reply.started":"2024-07-15T10:34:46.469130Z","shell.execute_reply":"2024-07-15T10:34:46.478069Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_data['word_count_prompt'] = train_data['prompt_clean'].apply(word_count)\ntrain_data['word_count_response_a'] = train_data['response_a_clean'].apply(word_count)\ntrain_data['word_count_response_b'] = train_data['response_b_clean'].apply(word_count)\ntrain_data['char_count_prompt'] = train_data['prompt_clean'].apply(char_count)\ntrain_data['char_count_response_a'] = train_data['response_a_clean'].apply(char_count)\ntrain_data['char_count_response_b'] = train_data['response_b_clean'].apply(char_count)\ntrain_data['lexical_diversity_prompt'] = train_data['prompt_clean'].apply(lexical_diversity)\ntrain_data['lexical_diversity_response_a'] = train_data['response_a_clean'].apply(lexical_diversity)\ntrain_data['lexical_diversity_response_b'] = train_data['response_b_clean'].apply(lexical_diversity)\ntrain_data['syllable_count_prompt'] = train_data['prompt_clean'].apply(syllable_count)\ntrain_data['syllable_count_response_a'] = train_data['response_a_clean'].apply(syllable_count)\ntrain_data['syllable_count_response_b'] = train_data['response_b_clean'].apply(syllable_count)\ntrain_data['sentence_count_prompt'] = train_data['prompt_clean'].apply(sentence_count)\ntrain_data['sentence_count_response_a'] = train_data['response_a_clean'].apply(sentence_count)\ntrain_data['sentence_count_response_b'] = train_data['response_b_clean'].apply(sentence_count)\ntrain_data['flesch_reading_ease_prompt'] = train_data['prompt_clean'].apply(flesch_reading_ease)\ntrain_data['flesch_reading_ease_response_a'] = train_data['response_a_clean'].apply(flesch_reading_ease)\ntrain_data['flesch_reading_ease_response_b'] = train_data['response_b_clean'].apply(flesch_reading_ease)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.481399Z","iopub.execute_input":"2024-07-15T10:34:46.481803Z","iopub.status.idle":"2024-07-15T10:34:46.555079Z","shell.execute_reply.started":"2024-07-15T10:34:46.481769Z","shell.execute_reply":"2024-07-15T10:34:46.553915Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Create BERT embeddings\n\nCompute BERT embeddings for prompt and response for both train and test data.\nAlso compute Cosine Similarity features using BERT between the prompt and responses for each model. \n\nI will use `tf.data.Dataset` to create an efficient pipeline, and process the features in batches using GPU. Also I am going to save the intermediate embeddings using `joblib` library","metadata":{}},{"cell_type":"code","source":"# Load BERT\nbert_model_name = 'bert-base-uncased'\nbert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\nbert_model = TFBertModel.from_pretrained(bert_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:46.556727Z","iopub.execute_input":"2024-07-15T10:34:46.557088Z","iopub.status.idle":"2024-07-15T10:34:52.940246Z","shell.execute_reply.started":"2024-07-15T10:34:46.557055Z","shell.execute_reply":"2024-07-15T10:34:52.939065Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cef12f1f8244b2181c396114a77a844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8531b920540749bfb26a466d269a11a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1bbc1b79cac48888ea1afadb5549976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"831e347c774b4bcf82cd9fa452ce613a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25a060346b7749ceb849d39d26478cff"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"@tf.function\ndef get_bert_embeddings(texts):\n    inputs = bert_tokenizer(texts, \n                       return_tensors='tf', \n                       padding=True, \n                       truncation=True, \n                       max_length=512)\n    outputs = bert_model(inputs)\n    return outputs.last_hidden_state[:, 0, :]","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:52.941823Z","iopub.execute_input":"2024-07-15T10:34:52.942183Z","iopub.status.idle":"2024-07-15T10:34:52.949586Z","shell.execute_reply.started":"2024-07-15T10:34:52.942133Z","shell.execute_reply":"2024-07-15T10:34:52.948307Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def process_column(column_data):\n    column_data = column_data.dropna().tolist()\n    column_data = [str(text) for text in column_data]  \n    dataset = tf.data.Dataset.from_tensor_slices(column_data)\n    dataset = dataset.batch(8)  \n    \n    embeddings = []\n    for batch in dataset:\n        batch_list = [str(text) for text in batch.numpy().tolist()]  \n        batch_embeddings = get_bert_embeddings(batch_list)\n        embeddings.append(batch_embeddings)\n    \n    return np.concatenate(embeddings, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:52.950899Z","iopub.execute_input":"2024-07-15T10:34:52.951293Z","iopub.status.idle":"2024-07-15T10:34:52.972941Z","shell.execute_reply.started":"2024-07-15T10:34:52.951260Z","shell.execute_reply":"2024-07-15T10:34:52.971525Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def add_embeddings_to_dataframe(df, column_names):\n    for column in column_names:\n        print(f\"Processing column: {column}\")\n        embeddings = process_column(df[column])\n        df[f'{column}_embedding'] = list(embeddings)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:52.974743Z","iopub.execute_input":"2024-07-15T10:34:52.975178Z","iopub.status.idle":"2024-07-15T10:34:52.983785Z","shell.execute_reply.started":"2024-07-15T10:34:52.975124Z","shell.execute_reply":"2024-07-15T10:34:52.982354Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"columns_to_embed = ['prompt_clean', 'response_a_clean', 'response_b_clean']","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:52.985495Z","iopub.execute_input":"2024-07-15T10:34:52.985878Z","iopub.status.idle":"2024-07-15T10:34:52.996250Z","shell.execute_reply.started":"2024-07-15T10:34:52.985846Z","shell.execute_reply":"2024-07-15T10:34:52.994963Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_data = add_embeddings_to_dataframe(train_data, columns_to_embed)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:34:52.997849Z","iopub.execute_input":"2024-07-15T10:34:52.998794Z","iopub.status.idle":"2024-07-15T10:39:58.701392Z","shell.execute_reply.started":"2024-07-15T10:34:52.998754Z","shell.execute_reply":"2024-07-15T10:39:58.700299Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Processing column: prompt_clean\nProcessing column: response_a_clean\nProcessing column: response_b_clean\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data['similarity_prompt_response_a'] = train_data.apply(\n    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)\n\ntrain_data['similarity_prompt_response_b'] = train_data.apply(\n    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.702927Z","iopub.execute_input":"2024-07-15T10:39:58.703400Z","iopub.status.idle":"2024-07-15T10:39:58.780638Z","shell.execute_reply.started":"2024-07-15T10:39:58.703357Z","shell.execute_reply":"2024-07-15T10:39:58.779496Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Data","metadata":{}},{"cell_type":"code","source":"X = train_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',\n                'char_count_prompt', 'char_count_response_a', 'char_count_response_b',\n                'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',\n                'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',\n                'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',\n                'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',\n                'similarity_prompt_response_a', 'similarity_prompt_response_b', \n                'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]\n","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.781950Z","iopub.execute_input":"2024-07-15T10:39:58.782321Z","iopub.status.idle":"2024-07-15T10:39:58.791644Z","shell.execute_reply.started":"2024-07-15T10:39:58.782289Z","shell.execute_reply":"2024-07-15T10:39:58.790528Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Definindo a coluna alvo\ntrain_data['winner'] = train_data.apply(lambda x: 0 if x['winner_model_a'] == 1 else (1 if x['winner_model_b'] == 1 else 2), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.793015Z","iopub.execute_input":"2024-07-15T10:39:58.793424Z","iopub.status.idle":"2024-07-15T10:39:58.809536Z","shell.execute_reply.started":"2024-07-15T10:39:58.793392Z","shell.execute_reply":"2024-07-15T10:39:58.807975Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y = train_data['winner']","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.811071Z","iopub.execute_input":"2024-07-15T10:39:58.811502Z","iopub.status.idle":"2024-07-15T10:39:58.820646Z","shell.execute_reply.started":"2024-07-15T10:39:58.811468Z","shell.execute_reply":"2024-07-15T10:39:58.819425Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Splitting training and validation data","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, \n                                                  random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.822473Z","iopub.execute_input":"2024-07-15T10:39:58.823040Z","iopub.status.idle":"2024-07-15T10:39:58.835465Z","shell.execute_reply.started":"2024-07-15T10:39:58.822995Z","shell.execute_reply":"2024-07-15T10:39:58.834233Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Defining Models\n\n* Random Forest\n* Logistic Regression\n* Support Vector Machin\n* Gradient Boosting\n* Neural Network","metadata":{}},{"cell_type":"code","source":"models = {\n    'Random Forest': RandomForestClassifier(),\n    'SVM': SVC(probability=True),\n    'Gradient Boosting': GradientBoostingClassifier()\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.837088Z","iopub.execute_input":"2024-07-15T10:39:58.837525Z","iopub.status.idle":"2024-07-15T10:39:58.846100Z","shell.execute_reply.started":"2024-07-15T10:39:58.837490Z","shell.execute_reply":"2024-07-15T10:39:58.844944Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Creating Neural Network\ndef create_nn_model(input_shape):\n    model = Sequential()\n    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(3, activation='softmax'))\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.847872Z","iopub.execute_input":"2024-07-15T10:39:58.848381Z","iopub.status.idle":"2024-07-15T10:39:58.857714Z","shell.execute_reply.started":"2024-07-15T10:39:58.848339Z","shell.execute_reply":"2024-07-15T10:39:58.856626Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"nn_model = create_nn_model(X_train.shape[1])\nmodels['Neural Network'] = nn_model","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.859381Z","iopub.execute_input":"2024-07-15T10:39:58.860205Z","iopub.status.idle":"2024-07-15T10:39:58.949196Z","shell.execute_reply.started":"2024-07-15T10:39:58.860164Z","shell.execute_reply":"2024-07-15T10:39:58.947845Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Training models and evaluating:","metadata":{}},{"cell_type":"code","source":"results = {}\n\nfor name, model in models.items():\n    print(f\"Treinando e avaliando {name}...\")\n    \n    if name == 'Neural Network':\n        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=2)\n        y_pred = np.argmax(model.predict(X_val), axis=1)\n        y_pred_proba = model.predict(X_val)\n    else:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_val)\n        y_pred_proba = model.predict_proba(X_val)\n\n    accuracy = accuracy_score(y_val, y_pred)\n    logloss = log_loss(y_val, y_pred_proba)\n\n    results[name] = {\n        'Acurácia': accuracy,\n        'Log Loss': logloss,\n        'Relatório de Classificação': classification_report(y_val, y_pred),\n        'Matriz de Confusão': confusion_matrix(y_val, y_pred)\n    }\n\n    print(f\"Acurácia de {name}: {accuracy}\")\n    print(f\"Log Loss de {name}: {logloss}\")\n    print(f\"Relatório de Classificação de {name}:\\n{classification_report(y_val, y_pred)}\")\n    print(f\"Matriz de Confusão de {name}:\\n{confusion_matrix(y_val, y_pred)}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:39:58.951172Z","iopub.execute_input":"2024-07-15T10:39:58.951637Z","iopub.status.idle":"2024-07-15T10:40:02.020860Z","shell.execute_reply.started":"2024-07-15T10:39:58.951595Z","shell.execute_reply":"2024-07-15T10:40:02.019202Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Treinando e avaliando Random Forest...\nAcurácia de Random Forest: 0.08333333333333333\nLog Loss de Random Forest: 1.181889026533914\nRelatório de Classificação de Random Forest:\n              precision    recall  f1-score   support\n\n           0       0.08      1.00      0.15         1\n           1       0.00      0.00      0.00         3\n           2       0.00      0.00      0.00         8\n\n    accuracy                           0.08        12\n   macro avg       0.03      0.33      0.05        12\nweighted avg       0.01      0.08      0.01        12\n\nMatriz de Confusão de Random Forest:\n[[1 0 0]\n [3 0 0]\n [8 0 0]]\n\nTreinando e avaliando SVM...\nAcurácia de SVM: 0.08333333333333333\nLog Loss de SVM: 1.1631561517105278\nRelatório de Classificação de SVM:\n              precision    recall  f1-score   support\n\n           0       0.08      1.00      0.15         1\n           1       0.00      0.00      0.00         3\n           2       0.00      0.00      0.00         8\n\n    accuracy                           0.08        12\n   macro avg       0.03      0.33      0.05        12\nweighted avg       0.01      0.08      0.01        12\n\nMatriz de Confusão de SVM:\n[[1 0 0]\n [3 0 0]\n [8 0 0]]\n\nTreinando e avaliando Gradient Boosting...\nAcurácia de Gradient Boosting: 0.08333333333333333\nLog Loss de Gradient Boosting: 1.2401426327927056\nRelatório de Classificação de Gradient Boosting:\n              precision    recall  f1-score   support\n\n           0       0.08      1.00      0.15         1\n           1       0.00      0.00      0.00         3\n           2       0.00      0.00      0.00         8\n\n    accuracy                           0.08        12\n   macro avg       0.03      0.33      0.05        12\nweighted avg       0.01      0.08      0.01        12\n\nMatriz de Confusão de Gradient Boosting:\n[[1 0 0]\n [3 0 0]\n [8 0 0]]\n\nTreinando e avaliando Neural Network...\nEpoch 1/10\n2/2 - 2s - 796ms/step - accuracy: 0.2444 - loss: 53.8406 - val_accuracy: 0.6667 - val_loss: 16.4867\nEpoch 2/10\n2/2 - 0s - 26ms/step - accuracy: 0.3111 - loss: 33.0373 - val_accuracy: 0.6667 - val_loss: 15.0786\nEpoch 3/10\n2/2 - 0s - 26ms/step - accuracy: 0.2889 - loss: 28.0296 - val_accuracy: 0.1667 - val_loss: 31.5069\nEpoch 4/10\n2/2 - 0s - 27ms/step - accuracy: 0.2889 - loss: 22.1006 - val_accuracy: 0.0833 - val_loss: 40.1335\nEpoch 5/10\n2/2 - 0s - 27ms/step - accuracy: 0.2667 - loss: 22.9042 - val_accuracy: 0.1667 - val_loss: 38.6171\nEpoch 6/10\n2/2 - 0s - 26ms/step - accuracy: 0.4667 - loss: 18.4676 - val_accuracy: 0.1667 - val_loss: 32.9518\nEpoch 7/10\n2/2 - 0s - 27ms/step - accuracy: 0.3556 - loss: 22.5570 - val_accuracy: 0.1667 - val_loss: 25.4555\nEpoch 8/10\n2/2 - 0s - 28ms/step - accuracy: 0.2667 - loss: 18.2360 - val_accuracy: 0.1667 - val_loss: 18.4994\nEpoch 9/10\n2/2 - 0s - 28ms/step - accuracy: 0.3778 - loss: 29.4195 - val_accuracy: 0.0833 - val_loss: 13.1288\nEpoch 10/10\n2/2 - 0s - 26ms/step - accuracy: 0.2222 - loss: 19.4529 - val_accuracy: 0.0833 - val_loss: 8.7733\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\nAcurácia de Neural Network: 0.08333333333333333\nLog Loss de Neural Network: 5.338416511639721\nRelatório de Classificação de Neural Network:\n              precision    recall  f1-score   support\n\n           0       0.08      1.00      0.15         1\n           1       0.00      0.00      0.00         3\n           2       0.00      0.00      0.00         8\n\n    accuracy                           0.08        12\n   macro avg       0.03      0.33      0.05        12\nweighted avg       0.01      0.08      0.01        12\n\nMatriz de Confusão de Neural Network:\n[[1 0 0]\n [3 0 0]\n [8 0 0]]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Selecting the best model with respect the Log Loss","metadata":{}},{"cell_type":"code","source":"best_model_name = max(results, key=lambda name: results[name]['Log Loss'])\nbest_model = models[best_model_name]","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.022929Z","iopub.execute_input":"2024-07-15T10:40:02.023456Z","iopub.status.idle":"2024-07-15T10:40:02.030486Z","shell.execute_reply.started":"2024-07-15T10:40:02.023412Z","shell.execute_reply":"2024-07-15T10:40:02.029099Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## Prediction and Submission\n\nPreparing test data, predicting on test data and creating submission data.","metadata":{}},{"cell_type":"code","source":"# Cleaning text from test data\ntest_data['prompt_clean'] = test_data['prompt'].apply(clean_text)\ntest_data['response_a_clean'] = test_data['response_a'].apply(clean_text)\ntest_data['response_b_clean'] = test_data['response_b'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.032348Z","iopub.execute_input":"2024-07-15T10:40:02.032815Z","iopub.status.idle":"2024-07-15T10:40:02.046864Z","shell.execute_reply.started":"2024-07-15T10:40:02.032778Z","shell.execute_reply":"2024-07-15T10:40:02.045704Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Tokenize text from test data\ntest_sequences = tokenizer.texts_to_sequences(test_data['prompt_clean'])\nresponse_a_test_sequences = tokenizer.texts_to_sequences(test_data['response_a_clean'])\nresponse_b_test_sequences = tokenizer.texts_to_sequences(test_data['response_b_clean'])","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.048561Z","iopub.execute_input":"2024-07-15T10:40:02.049560Z","iopub.status.idle":"2024-07-15T10:40:02.060016Z","shell.execute_reply.started":"2024-07-15T10:40:02.049512Z","shell.execute_reply":"2024-07-15T10:40:02.058788Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Padding sequences from test data\ntest_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post')\nresponse_a_test_sequences = pad_sequences(response_a_test_sequences, maxlen=max_len, padding='post')\nresponse_b_test_sequences = pad_sequences(response_b_test_sequences, maxlen=max_len, padding='post')","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.061838Z","iopub.execute_input":"2024-07-15T10:40:02.062371Z","iopub.status.idle":"2024-07-15T10:40:02.071771Z","shell.execute_reply.started":"2024-07-15T10:40:02.062330Z","shell.execute_reply":"2024-07-15T10:40:02.070235Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Sentiment analysis for test data\ntest_data['sentiment_prompt'] = test_data['prompt_clean'].apply(sentiment_analysis)\ntest_data['sentiment_response_a'] = test_data['response_a_clean'].apply(sentiment_analysis)\ntest_data['sentiment_response_b'] = test_data['response_b_clean'].apply(sentiment_analysis)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.073274Z","iopub.execute_input":"2024-07-15T10:40:02.073651Z","iopub.status.idle":"2024-07-15T10:40:02.087868Z","shell.execute_reply.started":"2024-07-15T10:40:02.073619Z","shell.execute_reply":"2024-07-15T10:40:02.086574Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Creating features of text structure from test data\ntest_data['word_count_prompt'] = test_data['prompt_clean'].apply(word_count)\ntest_data['word_count_response_a'] = test_data['response_a_clean'].apply(word_count)\ntest_data['word_count_response_b'] = test_data['response_b_clean'].apply(word_count)\ntest_data['char_count_prompt'] = test_data['prompt_clean'].apply(char_count)\ntest_data['char_count_response_a'] = test_data['response_a_clean'].apply(char_count)\ntest_data['char_count_response_b'] = test_data['response_b_clean'].apply(char_count)\ntest_data['lexical_diversity_prompt'] = test_data['prompt_clean'].apply(lexical_diversity)\ntest_data['lexical_diversity_response_a'] = test_data['response_a_clean'].apply(lexical_diversity)\ntest_data['lexical_diversity_response_b'] = test_data['response_b_clean'].apply(lexical_diversity)\ntest_data['syllable_count_prompt'] = test_data['prompt_clean'].apply(syllable_count)\ntest_data['syllable_count_response_a'] = test_data['response_a_clean'].apply(syllable_count)\ntest_data['syllable_count_response_b'] = test_data['response_b_clean'].apply(syllable_count)\ntest_data['sentence_count_prompt'] = test_data['prompt_clean'].apply(sentence_count)\ntest_data['sentence_count_response_a'] = test_data['response_a_clean'].apply(sentence_count)\ntest_data['sentence_count_response_b'] = test_data['response_b_clean'].apply(sentence_count)\ntest_data['flesch_reading_ease_prompt'] = test_data['prompt_clean'].apply(flesch_reading_ease)\ntest_data['flesch_reading_ease_response_a'] = test_data['response_a_clean'].apply(flesch_reading_ease)\ntest_data['flesch_reading_ease_response_b'] = test_data['response_b_clean'].apply(flesch_reading_ease)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.089469Z","iopub.execute_input":"2024-07-15T10:40:02.089988Z","iopub.status.idle":"2024-07-15T10:40:02.117195Z","shell.execute_reply.started":"2024-07-15T10:40:02.089945Z","shell.execute_reply":"2024-07-15T10:40:02.115839Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Embedding from test data\ntest_data = add_embeddings_to_dataframe(test_data, columns_to_embed)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:02.118583Z","iopub.execute_input":"2024-07-15T10:40:02.119023Z","iopub.status.idle":"2024-07-15T10:40:12.682698Z","shell.execute_reply.started":"2024-07-15T10:40:02.118990Z","shell.execute_reply":"2024-07-15T10:40:12.681274Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Processing column: prompt_clean\nProcessing column: response_a_clean\nProcessing column: response_b_clean\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cosine similarity from test data\ntest_data['similarity_prompt_response_a'] = test_data.apply(\n    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)\n\ntest_data['similarity_prompt_response_b'] = test_data.apply(\n    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:12.684291Z","iopub.execute_input":"2024-07-15T10:40:12.684691Z","iopub.status.idle":"2024-07-15T10:40:12.702179Z","shell.execute_reply.started":"2024-07-15T10:40:12.684656Z","shell.execute_reply":"2024-07-15T10:40:12.700706Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"X_test = test_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',\n                    'char_count_prompt', 'char_count_response_a', 'char_count_response_b',\n                    'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',\n                    'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',\n                    'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',\n                    'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',\n                    'similarity_prompt_response_a', 'similarity_prompt_response_b', \n                    'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:12.703587Z","iopub.execute_input":"2024-07-15T10:40:12.703966Z","iopub.status.idle":"2024-07-15T10:40:12.720270Z","shell.execute_reply.started":"2024-07-15T10:40:12.703935Z","shell.execute_reply":"2024-07-15T10:40:12.718688Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"test_pred_proba = best_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:12.722101Z","iopub.execute_input":"2024-07-15T10:40:12.722607Z","iopub.status.idle":"2024-07-15T10:40:12.855745Z","shell.execute_reply.started":"2024-07-15T10:40:12.722567Z","shell.execute_reply":"2024-07-15T10:40:12.854613Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame(test_data['id'])\nsubmission['winner_model_a'] = test_pred_proba[:, 0]\nsubmission['winner_model_b'] = test_pred_proba[:, 1]\nsubmission['winner_tie'] = test_pred_proba[:, 2]\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:12.857590Z","iopub.execute_input":"2024-07-15T10:40:12.857957Z","iopub.status.idle":"2024-07-15T10:40:12.870832Z","shell.execute_reply.started":"2024-07-15T10:40:12.857926Z","shell.execute_reply":"2024-07-15T10:40:12.869500Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:40:12.872415Z","iopub.execute_input":"2024-07-15T10:40:12.872888Z","iopub.status.idle":"2024-07-15T10:40:12.887076Z","shell.execute_reply.started":"2024-07-15T10:40:12.872850Z","shell.execute_reply":"2024-07-15T10:40:12.885780Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.780575        0.215729    0.003696\n1   211333        0.780575        0.215729    0.003696\n2  1233961        0.780575        0.215729    0.003696","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.780575</td>\n      <td>0.215729</td>\n      <td>0.003696</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.780575</td>\n      <td>0.215729</td>\n      <td>0.003696</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>0.780575</td>\n      <td>0.215729</td>\n      <td>0.003696</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}